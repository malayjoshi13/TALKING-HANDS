{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tJuzFaafkIg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import operator\n",
        "import cv2\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip this code block if you have already cloned the github repo in your GDrive\n",
        "\n",
        "\n",
        "# Change working directory to your Google Drive\n",
        "os.chdir('/content/drive/MyDrive/')\n",
        "\n",
        "# Cloning the repository in your Google Drive.\n",
        "# If you are doing inference right after doing training then no need to clone as during training process, this GitHub repo is cloned.\n",
        "!git clone https://github.com/malayjoshi13/TalkingHand.git"
      ],
      "metadata": {
        "id": "yRWUuU--foMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change working directory to your cloned repository\n",
        "os.chdir('/content/drive/MyDrive/TalkingHand/')"
      ],
      "metadata": {
        "id": "-0y1DZsmfrXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STOP!!\n",
        "\n",
        "1. Before moving ahead, go to your Google Drive. There you'll see folder named \"TalkingHand\" (which is cloned copy of the GitHub repo) we are working with. <br>\n",
        "\n",
        "2. Place the custom dataset folder which you would have custom created or if you want to use dataset created by me then by past this link (https://drive.google.com/drive/folders/1Fbn5kPQUAh-J1l09wmCAsIdMNwcjyVsh?usp=sharing) on your browser and create a shortcut of this dataset in the \"TalkingHand\" folder at your Google Drive.<br>\n",
        "\n",
        "3. Also place the weights from this link (https://drive.google.com/file/d/19tynPMUW8Ee9geskABT6QXKPkfXm9OiI/view?usp=sharing) to the \"TalkingHand\" folder by creating its shortcut also.\n",
        "\n",
        "4. Now lets's move to evaluation process below."
      ],
      "metadata": {
        "id": "7wVNu85Cfvao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU1wjjhzfkIi"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    return precision, recall, f1, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCz_Xd3sfkIi"
      },
      "outputs": [],
      "source": [
        "# Replace these paths with your actual paths\n",
        "model = load_model('weights.hdf5')\n",
        "test_dataset_path = \"./final_dataset/test\"\n",
        "\n",
        "# Iterate through each image in the test dataset\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for label_folder in os.listdir(test_dataset_path):\n",
        "    label_path = os.path.join(test_dataset_path, label_folder)\n",
        "\n",
        "    if os.path.isdir(label_path):\n",
        "        for image_file in os.listdir(label_path):\n",
        "            image_path = os.path.join(label_path, image_file)\n",
        "\n",
        "            # Load and preprocess the image\n",
        "            image = cv2.imread(image_path)\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            resized_roi = cv2.resize(gray, (64, 64))\n",
        "            channeled_mask = cv2.merge((resized_roi,resized_roi,resized_roi))\n",
        "            reshaped_mask = channeled_mask.reshape(1, 64, 64, 3)\n",
        "\n",
        "            # Make predictions using your model\n",
        "            result = model.predict(reshaped_mask)\n",
        "\n",
        "            # Then we create a dictonary to map probability position/indexing with label\n",
        "            prediction_dictionary ={'A': result[0][0],\n",
        "                        'B': result[0][1],\n",
        "                        'C': result[0][2],\n",
        "                        'SPACE': result[0][4],\n",
        "                        'DELETE': result[0][3],\n",
        "                        'D': result[0][5]\n",
        "                        }\n",
        "\n",
        "            prediction = sorted(prediction_dictionary.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "            # Next \"prediction[0][0]\" will pick up element at first position of variable \"prediction\"\n",
        "            top_label=prediction[0][0]\n",
        "\n",
        "            # Append true and predicted labels for later calculation\n",
        "            true_labels.append(label_folder)\n",
        "            predicted_labels.append(top_label)\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision, recall, f1, accuracy = calculate_metrics(true_labels, predicted_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExHoZgZOfkIk"
      },
      "outputs": [],
      "source": [
        "# Print the results\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Test accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}